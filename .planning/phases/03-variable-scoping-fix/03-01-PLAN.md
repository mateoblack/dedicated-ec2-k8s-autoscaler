---
phase: 03-variable-scoping-fix
plan: 01
type: execute
---

<objective>
Fix the CLUSTER_LOCK_HELD subshell variable propagation bug in the cleanup_on_failure() function.

Purpose: The cleanup function uses a pipe into a shell block which runs in a subshell, causing variable updates and error handling to not propagate to the parent shell. This can cause cleanup to fail silently.
Output: Fixed control-plane-bootstrap.ts with proper variable scoping that avoids subshell issues.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-phase.md
./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (dependency graph):
@.planning/phases/01-script-extraction/01-03-SUMMARY.md
@.planning/phases/02-retry-consolidation/02-01-SUMMARY.md

# Key files:
@lib/scripts/control-plane-bootstrap.ts

**Constraining decisions:**
- Phase 01-02: Bootstrap functions take stack parameter for region access
- Phase 02-01: Shared bash modules export functions returning script strings for interpolation

**Bug location:**
Lines 68-93 in control-plane-bootstrap.ts - the cleanup_on_failure() function pipes DynamoDB query output into Python, then into a `{ read ... }` block. The `{ }` block after a pipe runs in a subshell, so:
1. Variable updates inside won't propagate to parent
2. Exit codes from commands inside are lost
3. Error handling can't affect the parent shell

**Pattern to fix:**
```bash
# BROKEN: subshell variable scope
cmd | { read var; ... }

# FIXED: process substitution avoids subshell
while IFS= read -r line; do ...; done < <(cmd)

# OR: store in temp file
output=$(cmd)
# process $output
```
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix subshell variable scoping in cleanup_on_failure()</name>
  <files>lib/scripts/control-plane-bootstrap.ts</files>
  <action>
Rewrite lines 68-93 to avoid the subshell variable scope issue. The current pattern:
```bash
aws dynamodb query ... | python3 -c "..." | {
    read cluster_id
    read member_id
    if [ -n "$cluster_id" ] && [ -n "$member_id" ]; then
        aws dynamodb delete-item ...
    fi
}
```

Replace with a pattern that keeps variable scope in the parent shell. Use command substitution to capture Python output, then process it:

```bash
# Get member info from DynamoDB
member_info=$(aws dynamodb query \
    --table-name "${clusterName}-etcd-members" \
    --index-name "InstanceIdIndex" \
    --key-condition-expression "InstanceId = :iid" \
    --expression-attribute-values '{":iid":{"S":"'\$INSTANCE_ID'"}}' \
    --query 'Items[0]' \
    --output json --region $REGION 2>/dev/null || echo "{}")

# Parse with Python and capture output
read cluster_id member_id < <(echo "\$member_info" | python3 -c "
import sys, json
try:
    item = json.load(sys.stdin)
    if item:
        print(item.get('ClusterId', {}).get('S', ''), item.get('MemberId', {}).get('S', ''))
except:
    print('', '')
")

# Delete if we got valid IDs
if [ -n "\$cluster_id" ] && [ -n "\$member_id" ]; then
    aws dynamodb delete-item \
        --table-name "${clusterName}-etcd-members" \
        --key '{"ClusterId":{"S":"'\$cluster_id'"},"MemberId":{"S":"'\$member_id'"}}' \
        --region $REGION 2>/dev/null || true
fi
```

Key changes:
1. Split the pipeline into two steps - first capture DynamoDB output, then process
2. Use process substitution `< <(...)` to feed Python output to `read` in the parent shell
3. The `read cluster_id member_id` command now runs in the parent shell, not a subshell
4. Have Python print values space-separated on one line for simpler parsing

Note: Use `\$` for bash variables that should be interpolated at runtime, `$` for TypeScript template variables.
  </action>
  <verify>npm run build passes without TypeScript errors</verify>
  <done>cleanup_on_failure() no longer uses pipe-into-block pattern; variable reads happen in parent shell</done>
</task>

<task type="auto">
  <name>Task 2: Verify existing tests pass</name>
  <files>test/cluster-init-lock.test.ts</files>
  <action>
Run the existing cluster-init-lock tests to verify the refactored script still passes all assertions. The tests check:
- Bootstrap lock table usage (test-cluster-bootstrap-lock)
- Lock key schema (LockName, cluster-init)
- Condition expression for race prevention
- Lock cleanup on failure
- Lock release function exists
- SSM failure handling with lock release

If any tests fail, investigate and fix the issue in control-plane-bootstrap.ts. The behavior should be identical - only the implementation pattern changes.

Also run the full test suite to ensure no regressions.
  </action>
  <verify>npm test passes all tests including cluster-init-lock.test.ts</verify>
  <done>All 30+ test files pass, no regressions introduced</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `npm run build` succeeds without errors
- [ ] `npm test` passes all tests
- [ ] The pipe-into-block pattern `| { read ... }` no longer exists in cleanup_on_failure()
- [ ] Variable reads happen in parent shell scope (using process substitution or command substitution)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No TypeScript errors
- All existing tests pass
- The subshell variable scoping issue is fixed
</success_criteria>

<output>
After completion, create `.planning/phases/03-variable-scoping-fix/03-01-SUMMARY.md` following the summary template.
</output>
