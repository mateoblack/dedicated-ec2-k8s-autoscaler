---
phase: 10-cloudwatch-metrics
plan: 03
type: execute
---

<objective>
Integrate EMF metrics into Lambda functions to emit operational metrics.

Purpose: Add business-level metrics to Lambda functions - backup success/failure, etcd member removal duration, health check status - enabling CloudWatch dashboards and alarms on operational outcomes.
Output: Updated Lambda code generators emitting EMF metrics at key operation points.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-phase.md
./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-cloudwatch-metrics/10-01-SUMMARY.md
@.planning/phases/10-cloudwatch-metrics/10-02-SUMMARY.md

# Python metrics module:
@lib/scripts/python-metrics.ts

# Lambda functions to update:
@lib/scripts/etcd-lifecycle-lambda.ts
@lib/scripts/etcd-backup-lambda.ts
@lib/scripts/cluster-health-lambda.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add EMF metrics to etcd-lifecycle-lambda.ts</name>
  <files>lib/scripts/etcd-lifecycle-lambda.ts</files>
  <action>
Update createEtcdLifecycleLambdaCode to emit metrics:

1. Add import of getPythonMetricsSetup at top
2. Add ${getPythonMetricsSetup()} interpolation after logging setup
3. Create metrics logger at handler start: `metrics = create_metrics_logger('K8sCluster/EtcdLifecycle', context)`
4. Add metrics at key points:
   - After successful drain: `metrics.put_metric('NodeDrainSuccess', 1, COUNT)`
   - After failed drain: `metrics.put_metric('NodeDrainFailure', 1, COUNT)`
   - After successful etcd removal: `metrics.put_metric('EtcdMemberRemovalSuccess', 1, COUNT)`
   - After failed etcd removal: `metrics.put_metric('EtcdMemberRemovalFailure', 1, COUNT)`
   - On quorum risk: `metrics.put_metric('QuorumRiskDetected', 1, COUNT)`
   - At handler end (success path): Record duration metric `metrics.put_metric('LifecycleHandlerDuration', duration_ms, MILLISECONDS)`
5. Call `metrics.flush()` before each return statement

Duration calculation: capture start_time = time.time() * 1000 at handler start, calculate duration_ms = time.time() * 1000 - start_time at end.

IMPORTANT: Wrap metrics calls in try/except to prevent metrics failures from affecting Lambda behavior. Metrics are observability, not critical path.
  </action>
  <verify>Grep lib/scripts/etcd-lifecycle-lambda.ts for "put_metric" shows 5+ metric calls</verify>
  <done>etcd-lifecycle-lambda emits NodeDrain, EtcdMemberRemoval, QuorumRisk, and Duration metrics</done>
</task>

<task type="auto">
  <name>Task 2: Add EMF metrics to etcd-backup-lambda.ts</name>
  <files>lib/scripts/etcd-backup-lambda.ts</files>
  <action>
Update createEtcdBackupLambdaCode to emit metrics:

1. Add import of getPythonMetricsSetup at top
2. Add ${getPythonMetricsSetup()} interpolation after logging setup
3. Create metrics logger: `metrics = create_metrics_logger('K8sCluster/EtcdBackup', context)`
4. Add metrics:
   - On successful backup: `metrics.put_metric('BackupSuccess', 1, COUNT)`
   - On failed backup: `metrics.put_metric('BackupFailure', 1, COUNT)`
   - After backup: `metrics.put_metric('BackupDuration', duration_ms, MILLISECONDS)`
   - Parse backup size from output and emit: `metrics.put_metric('BackupSizeBytes', size, BYTES)`
5. Call `metrics.flush()` before each return statement

For BackupSizeBytes: The create_etcd_backup function already logs "BACKUP_SUCCESS key=... size=..." - parse the size from the command output and emit as metric.

IMPORTANT: Wrap metrics calls in try/except. Metrics failures should not cause backup to report failure.
  </action>
  <verify>Grep lib/scripts/etcd-backup-lambda.ts for "put_metric" shows 4+ metric calls</verify>
  <done>etcd-backup-lambda emits BackupSuccess, BackupFailure, BackupDuration, BackupSizeBytes metrics</done>
</task>

<task type="auto">
  <name>Task 3: Add EMF metrics to cluster-health-lambda.ts</name>
  <files>lib/scripts/cluster-health-lambda.ts</files>
  <action>
Update createClusterHealthLambdaCode to emit metrics:

1. Add import of getPythonMetricsSetup at top
2. Add ${getPythonMetricsSetup()} interpolation after logging setup
3. Create metrics logger: `metrics = create_metrics_logger('K8sCluster/Health', context)`
4. Add metrics:
   - Always emit healthy count: `metrics.put_metric('HealthyControlPlaneInstances', healthy_count, COUNT)`
   - Always emit failure count: `metrics.put_metric('ConsecutiveHealthFailures', failure_count, COUNT)`
   - On auto-recovery trigger: `metrics.put_metric('AutoRecoveryTriggered', 1, COUNT)`
   - On cluster recovered: `metrics.put_metric('ClusterRecovered', 1, COUNT)`
   - At handler end: `metrics.put_metric('HealthCheckDuration', duration_ms, MILLISECONDS)`
5. Call `metrics.flush()` before each return statement

IMPORTANT: Health check metrics are particularly valuable for dashboards. HealthyControlPlaneInstances should be emitted on every invocation (not just on change).
  </action>
  <verify>Grep lib/scripts/cluster-health-lambda.ts for "put_metric" shows 5+ metric calls</verify>
  <done>cluster-health-lambda emits HealthyInstances, FailureCount, AutoRecovery, Duration metrics</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run test:code` passes (no regressions)
- [ ] grep for "put_metric" in each Lambda file shows expected metrics
- [ ] grep for "metrics.flush()" in each Lambda file shows flush before returns
- [ ] grep for "getPythonMetricsSetup" in each Lambda file shows import
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No TypeScript errors
- Each Lambda emits 4-5 meaningful business metrics
- Metrics wrapped in try/except to prevent affecting Lambda behavior
</success_criteria>

<output>
After completion, create `.planning/phases/10-cloudwatch-metrics/10-03-SUMMARY.md`
</output>
